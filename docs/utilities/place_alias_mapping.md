# Place Alias Mapping Utility

**Script:** `scripts/normalization/generate_place_alias_map.py`

**Purpose:** Generate canonical English place name mappings from frequency analysis using LLM-assisted normalization

**Input:** `data/frequency/places_freq.csv` (from `build_place_freq.py`)

**Output:**
- `place_alias_map.json` - Production mappings for M2 normalization
- `place_alias_cache.jsonl` - LLM call cache (for incremental updates)
- `place_alias_proposed.csv` - Human review file with all decisions

---

## Prerequisites

### 1. Environment Setup

Create `.env` file with OpenAI API key:

```bash
# .env
OPENAI_API_KEY=sk-...
```

### 2. Dependencies

Ensure required packages are installed:

```bash
pip install openai pydantic
```

### 3. Input Data

Run place frequency analysis first:

```bash
python -m scripts.marc.build_place_freq \
  data/marc_source/BIBLIOGRAPHIC_*.xml \
  data/frequency/places_freq.csv \
  data/frequency/places_examples.json
```

---

## Basic Usage

### Generate Place Alias Map

```bash
python scripts/normalization/generate_place_alias_map.py \
  --input data/frequency/places_freq.csv \
  --output data/normalization/place_aliases/place_alias_map.json \
  --cache data/normalization/place_aliases/place_alias_cache.jsonl \
  --proposed data/normalization/place_aliases/place_alias_proposed.csv \
  --min-conf 0.85
```

**What happens:**

1. Reads place frequencies from CSV
2. Applies auto-rules for obvious cases (already canonical, bracket stripping, etc.)
3. Calls LLM for remaining places (with caching)
4. Filters decisions by confidence threshold
5. Writes three output files

**First run:** Processes all places via LLM (costs ~$3-5 for typical dataset)

**Subsequent runs:** Uses cache, only processes new places (costs ~$0.01-0.05 per new place)

---

## Command-Line Options

### Required Arguments

**`--input PATH`**
- Path to place frequency CSV
- Format: `place_norm,count`
- Generated by `build_place_freq.py`

**`--output PATH`**
- Path to production mapping JSON
- Only includes MAP decisions with confidence ≥ min-conf
- Used by M2 normalization

**`--cache PATH`**
- Path to LLM cache file (JSONL)
- Append-only, one JSON per line
- Prevents redundant API calls

**`--proposed PATH`**
- Path to human review CSV
- All decisions with metadata
- Includes auto-rules and LLM calls

### Optional Arguments

**`--min-conf FLOAT`** (default: 0.85)
- Minimum confidence for production map
- Range: 0.0-1.0
- Lower = more mappings (higher recall, lower precision)
- Higher = fewer mappings (lower recall, higher precision)

**`--primary-model MODEL`** (default: gpt-4o)
- OpenAI model for primary mapping
- Options: `gpt-4o`, `gpt-4-turbo`, `gpt-4`, `gpt-4o-mini`
- More expensive models = better accuracy

**`--fallback-model MODEL`** (default: gpt-4o-mini)
- Cheaper model for uncertain cases
- Only used if primary returns low confidence (<0.75) or AMBIGUOUS/UNKNOWN
- Cost savings: ~$0.0003 vs ~$0.005 per call

**`--max-places INT`** (default: unlimited)
- Limit number of places to process
- Useful for testing and cost estimation
- Example: `--max-places 100` to test first 100 places

---

## Workflow Examples

### Example 1: Initial Generation (Full Dataset)

```bash
# Step 1: Run frequency analysis
python -m scripts.marc.build_place_freq \
  data/marc_source/BIBLIOGRAPHIC_*.xml \
  data/frequency/places_freq.csv \
  data/frequency/places_examples.json

# Step 2: Generate alias map (full run)
python scripts/normalization/generate_place_alias_map.py \
  --input data/frequency/places_freq.csv \
  --output data/normalization/place_aliases/place_alias_map.json \
  --cache data/normalization/place_aliases/place_alias_cache.jsonl \
  --proposed data/normalization/place_aliases/place_alias_proposed.csv

# Expected output:
# - 838 places processed
# - ~150 handled by auto-rules (free)
# - ~688 LLM calls needed
# - ~$3.50 total cost
# - 383 mappings in production file (≥0.85 confidence)
```

### Example 2: Test Run (Cost Estimation)

```bash
# Process only first 100 places to estimate costs
python scripts/normalization/generate_place_alias_map.py \
  --input data/frequency/places_freq.csv \
  --output data/normalization/place_aliases/place_alias_map_test.json \
  --cache data/normalization/place_aliases/place_alias_cache_test.jsonl \
  --proposed data/normalization/place_aliases/place_alias_proposed_test.csv \
  --max-places 100

# Expected output:
# - 100 places processed
# - ~18 auto-rules
# - ~82 LLM calls
# - ~$0.41 cost
# - Scales linearly to full dataset
```

### Example 3: Incremental Update (New Places)

```bash
# Scenario: New MARC records added, frequency analysis updated

# Step 1: Update frequency analysis
python -m scripts.marc.build_place_freq \
  data/marc_source/BIBLIOGRAPHIC_*.xml \
  data/frequency/places_freq.csv \
  data/frequency/places_examples.json

# Step 2: Run alias generation (uses cache!)
python scripts/normalization/generate_place_alias_map.py \
  --input data/frequency/places_freq.csv \
  --output data/normalization/place_aliases/place_alias_map.json \
  --cache data/normalization/place_aliases/place_alias_cache.jsonl \
  --proposed data/normalization/place_aliases/place_alias_proposed.csv

# Expected output:
# - Cache hit rate: ~95%
# - Only ~40 new places need LLM
# - ~$0.20 cost
# - Production map updated with new entries
```

### Example 4: Conservative Mapping (High Precision)

```bash
# Use higher confidence threshold for production
python scripts/normalization/generate_place_alias_map.py \
  --input data/frequency/places_freq.csv \
  --output data/normalization/place_aliases/place_alias_map.json \
  --cache data/normalization/place_aliases/place_alias_cache.jsonl \
  --proposed data/normalization/place_aliases/place_alias_proposed.csv \
  --min-conf 0.90

# Result:
# - Fewer mappings (~250 instead of 383)
# - Higher precision (fewer errors)
# - Lower recall (more unmapped variants)
```

### Example 5: Cheap Model for Testing

```bash
# Use gpt-4o-mini for all calls (10x cheaper)
python scripts/normalization/generate_place_alias_map.py \
  --input data/frequency/places_freq.csv \
  --output data/normalization/place_aliases/place_alias_map_cheap.json \
  --cache data/normalization/place_aliases/place_alias_cache_cheap.jsonl \
  --proposed data/normalization/place_aliases/place_alias_proposed_cheap.csv \
  --primary-model gpt-4o-mini \
  --fallback-model gpt-4o-mini

# Result:
# - ~$0.35 total cost (vs ~$3.50)
# - Slightly lower quality
# - Good enough for development/testing
```

---

## Output File Formats

### 1. place_alias_map.json (Production)

**Purpose:** Used by M2 normalization for place lookups

**Format:**
```json
{
  "'s-gravenhage": "the hague",
  "[amsterdam]": "amsterdam",
  "אמשטרדם": "amsterdam",
  "lipsiae": "leipzig",
  "münchen": "munich",
  "à paris": "paris"
}
```

**Filtering criteria:**
- Only `MAP` decisions
- Confidence ≥ `--min-conf` threshold
- Canonical keys validated (lowercase ASCII)

**Usage:**
```bash
python -m scripts.marc.m2_normalize \
  data/canonical/records.jsonl \
  data/m2/records_m1m2.jsonl \
  --place-alias data/normalization/place_aliases/place_alias_map.json
```

### 2. place_alias_cache.jsonl (Cache)

**Purpose:** Prevents redundant LLM calls

**Format (one JSON per line):**
```json
{"place_norm": "אמשטרדם", "canonical": "amsterdam", "decision": "MAP", "confidence": 0.99, "notes": "Hebrew for Amsterdam", "method": "llm_primary", "count": 85}
{"place_norm": "paris", "canonical": "paris", "decision": "KEEP", "confidence": 0.9, "notes": "already canonical", "method": "auto_rule", "count": 273}
{"place_norm": "[s.l.]", "canonical": "s.l.", "decision": "KEEP", "confidence": 0.95, "notes": "placeholder preserved", "method": "auto_rule", "count": 22}
```

**Fields:**
- `place_norm` - Input from frequency CSV
- `canonical` - Proposed canonical key
- `decision` - KEEP | MAP | AMBIGUOUS | UNKNOWN
- `confidence` - 0.0-1.0
- `notes` - Explanation
- `method` - auto_rule | llm_primary | llm_fallback
- `count` - Frequency from input CSV

**Maintenance:**
- Append-only (never modified)
- Safe to delete to force full regeneration
- Can be manually edited (add/remove lines)

### 3. place_alias_proposed.csv (Human Review)

**Purpose:** Complete audit trail for validation

**Format:**
```csv
place_norm,canonical,decision,confidence,method,count,notes
paris,paris,KEEP,0.9,auto_rule,273,already canonical
אמשטרדם,amsterdam,MAP,0.99,llm_primary,85,Hebrew for Amsterdam
[amsterdam],[amsterdam],MAP,0.9,auto_rule,50,bracketed variant
frankfurt,frankfurt,AMBIGUOUS,0.0,auto_rule,23,multiple cities possible
obscure_place,obscure_place,UNKNOWN,0.0,llm_invalid_fallback,1,LLM failed validation
```

**Columns:**
- `place_norm` - Input variant
- `canonical` - Proposed mapping
- `decision` - KEEP | MAP | AMBIGUOUS | UNKNOWN
- `confidence` - 0.0-1.0
- `method` - Traceability
- `count` - Frequency (for prioritizing review)
- `notes` - Human-readable explanation

**Review workflow:**
1. Sort by `count` (descending) - high-frequency errors have biggest impact
2. Filter `decision == MAP` AND `confidence < 0.90` - review uncertain mappings
3. Check `decision == UNKNOWN` - identify patterns for auto-rules
4. Validate `decision == AMBIGUOUS` - confirm truly ambiguous

---

## Auto-Rules (No LLM Needed)

### 1. Already Canonical (KEEP)

**Pattern:** Lowercase ASCII, space-separated words

**Regex:** `^[a-z0-9]+(?: [a-z0-9]+)*$`

**Examples:**
- `london` → KEEP
- `new york` → KEEP
- `tel aviv` → KEEP

**Confidence:** 0.95

### 2. Bracket Stripping (MAP)

**Pattern:** `[canonical_key]` where inner text is canonical

**Examples:**
- `[paris]` → `paris`
- `[amsterdam]` → `amsterdam`

**Confidence:** 0.90

### 3. Placeholder Preservation (KEEP)

**Pattern:** Special abbreviations

**Whitelist:** `s.l.` (sine loco - "without place")

**Examples:**
- `s.l.` → KEEP
- `[s.l.]` → KEEP

**Confidence:** 0.95

### 4. Known Ambiguous (AMBIGUOUS)

**Pattern:** Hardcoded list of inherently ambiguous places

**Examples:**
- `frankfurt` (am Main vs. an der Oder)
- `alexandria` (Egypt vs. US cities)
- `newcastle` (UK vs. Australia)

**Confidence:** 0.0 (no mapping)

**Rationale:** Requires additional context to disambiguate

---

## LLM Processing

### Prompt Structure

The script uses OpenAI's Structured Responses API with Pydantic schemas:

```
Given a normalized place name from bibliographic records, map it to a canonical English key.

Input: אמשטרדם
Count: 85 occurrences

Canonical key policy:
- Lowercase ASCII only
- Words separated by single spaces
- Examples: "london", "new york", "tel aviv"

Output structured JSON with:
{
  "canonical": "amsterdam",
  "decision": "MAP",
  "confidence": 0.99,
  "notes": "Hebrew for Amsterdam"
}

Decisions:
- KEEP: Input is already canonical
- MAP: Map to canonical form
- AMBIGUOUS: Multiple valid places (no mapping)
- UNKNOWN: Cannot determine
```

### Post-Processing

All LLM outputs are validated and normalized:

1. Casefold to lowercase
2. Replace hyphens/underscores with spaces
3. Remove punctuation
4. Collapse whitespace
5. Validate against canonical regex
6. Reject if validation fails (mark as UNKNOWN)

### Fallback Strategy

If primary model returns:
- Confidence < 0.75
- Decision = AMBIGUOUS
- Decision = UNKNOWN

Then:
1. Retry with fallback model (cheaper)
2. Use higher of two confidence scores
3. If still uncertain, mark as UNKNOWN

---

## Cost Estimation

### Pricing (as of 2025)

- **gpt-4o:** ~$0.005 per call
- **gpt-4o-mini:** ~$0.0003 per call
- **gpt-4-turbo:** ~$0.008 per call

### Reference Dataset Costs

**Total places:** 838

**Auto-rule coverage:** ~150 places (18%)
- Cost: $0.00 (no API calls)

**LLM needed:** ~688 places (82%)

**Primary model calls:** ~688
- Cost: 688 × $0.005 = $3.44

**Fallback model calls:** ~50 (for uncertain cases)
- Cost: 50 × $0.0003 = $0.015

**Total estimated cost:** ~$3.50

### Scaling

- **Linear scaling:** 1,000 places ≈ $4.50
- **Incremental updates:** Only new places are processed
- **Cache effectiveness:** 95%+ hit rate on re-runs
- **Cost per new place:** $0.005-0.008

---

## Quality Control

### Review High-Frequency Mappings

```bash
# Sort proposed CSV by count (descending)
sort -t, -k6 -rn place_alias_proposed.csv | head -50

# Review top 50 most frequent places
# These have biggest impact on data quality
```

### Check Low-Confidence Mappings

```bash
# Filter MAP decisions with confidence < 0.90
awk -F, '$3 == "MAP" && $4 < 0.90 {print}' place_alias_proposed.csv

# Review and validate uncertain mappings
```

### Identify UNKNOWN Patterns

```bash
# Find all UNKNOWN decisions
awk -F, '$3 == "UNKNOWN" {print}' place_alias_proposed.csv

# Look for patterns that could become auto-rules
```

### Validate Production Map

```bash
# Count entries in production map
jq 'length' place_alias_map.json

# Check for unexpected keys
jq -r 'keys[]' place_alias_map.json | grep -v '^[a-z0-9 ]*$'

# Verify all values are canonical
jq -r 'values[]' place_alias_map.json | grep -v '^[a-z0-9 ]*$'
```

---

## Troubleshooting

### Issue: High costs

**Symptoms:** Unexpected API charges

**Solutions:**
1. Use `--max-places 100` for testing
2. Ensure cache file is being used
3. Consider cheaper primary model: `--primary-model gpt-4o-mini`
4. Check for duplicate calls (cache corruption)

### Issue: Too many UNKNOWN

**Symptoms:** High percentage of unmapped places

**Solutions:**
1. Review `notes` column in proposed CSV for patterns
2. Add patterns to auto-rules in script
3. Adjust LLM prompt for better guidance
4. Use more powerful primary model: `--primary-model gpt-4o`

### Issue: Invalid canonical keys

**Symptoms:** Uppercase, punctuation, or non-ASCII in production map

**Solutions:**
1. Check post-processing logic in script
2. Verify Pydantic validation is enabled
3. Manually clean production JSON
4. Regenerate with fixed script

### Issue: Ambiguous places mapped incorrectly

**Symptoms:** Frankfurt conflated, Alexandria mixed

**Solutions:**
1. Add to `ALWAYS_AMBIGUOUS` set in script:
   ```python
   ALWAYS_AMBIGUOUS = {
       "frankfurt",
       "alexandria",
       "newcastle",
       "your_ambiguous_place",
   }
   ```
2. Delete cache entries for affected places
3. Regenerate

### Issue: Cache corruption

**Symptoms:** Inconsistent results, unexpected LLM calls

**Solutions:**
1. Backup cache: `cp place_alias_cache.jsonl place_alias_cache.jsonl.bak`
2. Delete corrupted cache: `rm place_alias_cache.jsonl`
3. Regenerate from scratch
4. Costs will be incurred again

---

## Integration with M2 Normalization

### Automatic Loading

The `m2_normalize.py` script automatically loads the place alias map if provided:

```bash
python -m scripts.marc.m2_normalize \
  data/canonical/records.jsonl \
  data/m2/records_m1m2.jsonl \
  --place-alias data/normalization/place_aliases/place_alias_map.json
```

### Default Path

As of the reorganization, the default path is:
```
data/normalization/place_aliases/place_alias_map.json
```

This file is tracked in git (exception to data/ gitignore).

### Confidence Boost

When alias map is used:
- **Without map:** confidence 0.80, method `place_casefold_strip`
- **With map:** confidence 0.95, method `place_alias_map`

This higher confidence signals that the normalization is curated and validated.

---

## See Also

- [Place Normalization Pipeline](../pipelines/place_normalization.md) - Full workflow overview
- [Place Frequency Specification](../specs/place_frequency_spec.md) - Input data generation
- [M2 Normalization Specification](../specs/m2_normalization_spec.md) - Integration with M2 enrichment
